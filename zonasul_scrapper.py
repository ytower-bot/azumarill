import requests
from bs4 import BeautifulSoup
import json
import time
import re
import pandas as pd
from urllib.parse import quote

# Configura√ß√µes b√°sicas
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
}

def separar_nome_quantidade(nome_bruto):
    """
    Separa o nome do produto da quantidade.
    Procura por padr√µes como: 180g, 600g, 1kg, 500ml, Com 10 Unidades, etc.
    Retorna: (nome_limpo, quantidade, unidade)
    Se n√£o encontrar quantidade: (nome_limpo, "-", "-")
    """
    if not nome_bruto:
        return ("-", "-", "-")
    
    # Padr√£o 1: n√∫mero seguido de unidade no final (180g, 600g, 1kg, 500ml, etc)
    padrao_final = r'(\d+(?:[.,]\d+)?)\s*(g|kg|ml|l)\s*$'
    
    # Padr√£o 2: "Com X Unidades" ou "X Unidades" no final
    padrao_unidades = r'(?:com\s+)?(\d+(?:[.,]\d+)?)\s*(unidades?|un\.?)\s*$'
    
    # Tenta padr√£o final primeiro (mais comum)
    match = re.search(padrao_final, nome_bruto, re.IGNORECASE)
    
    if not match:
        # Tenta padr√£o de unidades
        match = re.search(padrao_unidades, nome_bruto, re.IGNORECASE)
    
    if match:
        # Encontrou quantidade
        quantidade = match.group(1)
        unidade = match.group(2).lower()
        
        # Remove a quantidade do nome (incluindo "Com" se existir)
        nome_limpo = nome_bruto[:match.start()].strip()
        # Remove "Com" se ficou no final do nome
        nome_limpo = re.sub(r'\s+[Cc]om\s*$', '', nome_limpo).strip()
        
        return (nome_limpo, quantidade, unidade)
    else:
        # N√£o encontrou quantidade
        return (nome_bruto.strip(), "-", "-")

def buscar_pagina(url, mostrar_log=False):
    """Faz a requisi√ß√£o e retorna o BeautifulSoup"""
    try:
        if mostrar_log:
            print(f"Acessando: {url}")
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser'), response.status_code
    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar {url}: {e}")
        return None, None

def extrair_produtos_jsonld(soup):
    """Extrai produtos do JSON-LD estruturado"""
    produtos = []
    
    # Procura scripts JSON-LD
    scripts = soup.find_all('script', type='application/ld+json')
    
    for script in scripts:
        try:
            data = json.loads(script.string)
            
            # Verifica se √© uma lista de produtos
            if data.get('@type') == 'ItemList' and 'itemListElement' in data:
                for item in data['itemListElement']:
                    produto_item = item.get('item', {})
                    
                    if produto_item.get('@type') == 'Product':
                        nome = produto_item.get('name', '')
                        preco_info = produto_item.get('offers', {})
                        
                        # Tenta pegar o pre√ßo
                        preco = None
                        if isinstance(preco_info, dict):
                            preco = preco_info.get('price') or preco_info.get('lowPrice')
                        
                        if nome:
                            produtos.append({
                                'nome_bruto': nome,
                                'preco_bruto': preco
                            })
        except json.JSONDecodeError:
            continue
        except Exception as e:
            print(f"Erro ao processar JSON-LD: {e}")
            continue
    
    return produtos

def classificar_tipo_produto(nome_produto):
    """
    Classifica o tipo do produto baseado no nome.
    Retorna: 'hortifruti', 'mercearia', 'frios e laticinios', 'carnes' ou 'processados'
    """
    if not nome_produto:
        return 'processados'
    
    nome_lower = nome_produto.lower()
    
    # Hortifruti: frutas, verduras, legumes, hortali√ßas
    palavras_hortifruti = [
        'fruta', 'verdura', 'legume', 'hortali√ßa', 'folha',
        'banana', 'ma√ß√£', 'laranja', 'tomate', 'cebola', 'alho',
        'batata', 'cenoura', 'abobrinha', 'berinjela', 'piment√£o',
        'alface', 'r√∫cula', 'couve', 'repolho', 'br√≥colis',
        'morango', 'uva', 'mam√£o', 'abacate', 'lim√£o',
        'chuchu', 'ab√≥bora', 'quiabo', 'vagem', 'pepino'
    ]
    
    if any(palavra in nome_lower for palavra in palavras_hortifruti):
        return 'hortifruti'
    
    # Carnes: carnes, aves, peixes
    palavras_carnes = [
        'carne', 'frango', 'peixe', 'porco', 'bovino', 'su√≠no',
        'bife', 'alcatra', 'picanha', 'maminha', 'contra-fil√©',
        'coxinha', 'sobrecoxa', 'peito', 'salm√£o', 'til√°pia',
        'sardinha', 'atum', 'lingui√ßa', 'salsicha', 'embutido'
    ]
    
    if any(palavra in nome_lower for palavra in palavras_carnes):
        return 'carnes'
    
    # Frios e Latic√≠nios: queijos, iogurtes, leites, requeij√£o, etc.
    palavras_frios_laticinios = [
        'queijo', 'iogurte', 'leite', 'requeij√£o', 'manteiga',
        'nata', 'creme de leite', 'ricota', 'cottage', 'mussarela',
        'presunto', 'mortadela', 'salame', 'peito de peru',
        'latic√≠nio', 'laticinio'
    ]
    
    if any(palavra in nome_lower for palavra in palavras_frios_laticinios):
        return 'frios e laticinios'
    
    # Mercearia: gr√£os, cereais, farinhas, a√ß√∫cares, √≥leos, etc.
    palavras_mercearia = [
        'arroz', 'feij√£o', 'lentilha', 'gr√£o', 'cereal', 'aveia', 'quinoa',
        'farinha', 'trigo', 'milho', 'soja', 'castanha', 'amendoim', 'nozes',
        'a√ß√∫car', 'sal', '√≥leo', 'azeite', 'vinagre', 'macarr√£o', 'massa',
        'biscoito', 'bolacha', 'caf√©', 'ch√°', 'mel', 'geleia'
    ]
    
    if any(palavra in nome_lower for palavra in palavras_mercearia):
        return 'mercearia'
    
    # Processados: padaria, confeitaria, bebidas, condimentos, congelados, etc.
    # Se n√£o se encaixou em nenhuma categoria acima, vai para processados
    return 'processados'

def coletar_todas_paginas(url_base, max_paginas=50):
    """
    Coleta produtos de todas as p√°ginas dispon√≠veis.
    Para quando n√£o encontrar mais produtos ou der erro.
    Retorna lista de todos os produtos coletados.
    """
    todos_produtos = []
    pagina = 1
    formato_pagina = None
    urls_visitadas = set()  # Para evitar loops infinitos
    produtos_por_pagina = []  # Para detectar p√°ginas repetidas
    
    print(f"\n{'='*60}")
    print(f"Iniciando coleta de todas as p√°ginas")
    print(f"URL base: {url_base}")
    print(f"Limite m√°ximo de p√°ginas: {max_paginas}")
    print(f"{'='*60}\n")
    
    while pagina <= max_paginas:
        # Monta URL da p√°gina
        if pagina == 1:
            url = url_base
        else:
            # Detecta formato de pagina√ß√£o na p√°gina 2
            if pagina == 2 and formato_pagina is None:
                # Tenta diferentes formatos de pagina√ß√£o
                formatos_teste = []
                if '?' in url_base:
                    formatos_teste = [
                        f"{url_base}&page={pagina}",
                        f"{url_base}&_page={pagina}",
                        f"{url_base}&from={((pagina-1)*50)}",
                    ]
                else:
                    formatos_teste = [
                        f"{url_base}?page={pagina}",
                        f"{url_base}?_page={pagina}",
                        f"{url_base}?from={((pagina-1)*50)}",
                    ]
                
                # Testa cada formato
                for url_teste in formatos_teste:
                    soup_test, status_test = buscar_pagina(url_teste, mostrar_log=False)
                    if soup_test and status_test == 200:
                        produtos_test = extrair_produtos_jsonld(soup_test)
                        if len(produtos_test) > 0:
                            url = url_teste
                            if '&page=' in url_teste or '?page=' in url_teste:
                                formato_pagina = 'page'
                            elif '&_page=' in url_teste or '?_page=' in url_teste:
                                formato_pagina = '_page'
                            elif '&from=' in url_teste or '?from=' in url_teste:
                                formato_pagina = 'from'
                            print(f"   ‚úÖ Formato de pagina√ß√£o detectado: {formato_pagina}")
                            break
                
                if formato_pagina is None:
                    formato_pagina = 'page'
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
            else:
                # Usa o formato detectado
                if formato_pagina == 'page':
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
                elif formato_pagina == '_page':
                    if '?' in url_base:
                        url = f"{url_base}&_page={pagina}"
                    else:
                        url = f"{url_base}?_page={pagina}"
                elif formato_pagina == 'from':
                    offset = (pagina - 1) * 50
                    if '?' in url_base:
                        url = f"{url_base}&from={offset}"
                    else:
                        url = f"{url_base}?from={offset}"
                else:
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
        
        print(f"üìÑ P√°gina {pagina}: {url}")
        
        # Verifica se j√° visitou esta URL (prote√ß√£o contra loop)
        if url in urls_visitadas:
            print(f"‚ö†Ô∏è  URL j√° visitada anteriormente. Parando para evitar loop infinito.")
            break
        urls_visitadas.add(url)
        
        # Busca a p√°gina
        soup, status = buscar_pagina(url)
        
        # Se deu erro ao buscar, para
        if soup is None or status != 200:
            print(f"‚ùå Erro ou p√°gina n√£o encontrada. Parando na p√°gina {pagina}")
            break
        
        # Extrai produtos da p√°gina
        produtos_pagina = extrair_produtos_jsonld(soup)
        
        # Se n√£o encontrou produtos, acabaram as p√°ginas
        if len(produtos_pagina) == 0:
            print(f"‚úÖ Fim das p√°ginas (p√°gina {pagina} n√£o tem produtos)")
            break
        
        # Verifica se esta p√°gina tem os mesmos produtos da anterior (prote√ß√£o contra loop)
        if produtos_por_pagina and len(produtos_por_pagina) > 0:
            # Pega os nomes dos produtos da p√°gina anterior
            nomes_anterior = {p['nome_bruto'] for p in produtos_por_pagina[-1]}
            nomes_atual = {p['nome_bruto'] for p in produtos_pagina}
            
            # Se os produtos s√£o exatamente iguais, pode ser loop
            if nomes_anterior == nomes_atual and len(nomes_anterior) > 0:
                print(f"‚ö†Ô∏è  P√°gina {pagina} tem os mesmos produtos da p√°gina anterior. Parando para evitar loop.")
                break
        
        # Guarda produtos desta p√°gina para compara√ß√£o
        produtos_por_pagina.append(produtos_pagina.copy())
        
        # Adiciona categoria, tipo e metadados
        for produto in produtos_pagina:
            # A categoria ser√° definida pela fun√ß√£o que chama esta fun√ß√£o
            if 'categoria' not in produto:
                produto['categoria'] = 'N√£o Org√¢nico'  # Padr√£o
            produto['tipo'] = classificar_tipo_produto(produto['nome_bruto'])
            produto['url_origem'] = url
        
        # Adiciona produtos encontrados
        todos_produtos.extend(produtos_pagina)
        print(f"   ‚úÖ {len(produtos_pagina)} produtos encontrados (Total: {len(todos_produtos)})\n")
        
        pagina += 1
        
        # Delay para n√£o sobrecarregar o servidor
        time.sleep(1)
    
    if pagina > max_paginas:
        print(f"‚ö†Ô∏è  Limite m√°ximo de {max_paginas} p√°ginas atingido.")
    
    print(f"\n{'='*60}")
    print(f"Coleta conclu√≠da: {len(todos_produtos)} produtos em {pagina-1} p√°ginas")
    print(f"{'='*60}\n")
    
    return todos_produtos

def buscar_produtos_por_termo(termo_busca):
    """
    Busca produtos org√¢nicos por termo usando o formato correto:
    https://www.zonasul.com.br/organico?_q={termo}&map=ft
    Retorna lista de produtos encontrados.
    """
    # Codifica o termo de busca para URL
    termo_encoded = quote(termo_busca, safe='')
    
    # URL de busca do Zona Sul no formato correto
    url_busca = f'https://www.zonasul.com.br/organico?_q={termo_encoded}&map=ft'
    
    print(f"\nüîç Buscando por termo: '{termo_busca}'")
    print(f"   URL: {url_busca}")
    
    # Verifica se a URL existe e tem produtos
    soup, status = buscar_pagina(url_busca, mostrar_log=False)
    
    if soup is not None and status == 200:
        produtos_teste = extrair_produtos_jsonld(soup)
        if len(produtos_teste) > 0:
            print(f"   ‚úÖ URL de busca acess√≠vel com produtos encontrados")
            produtos = coletar_todas_paginas(url_busca)
            print(f"   üìä {len(produtos)} produtos encontrados para '{termo_busca}'")
            return produtos
        else:
            print(f"   ‚ö†Ô∏è  URL acess√≠vel mas nenhum produto encontrado na primeira p√°gina")
    else:
        print(f"   ‚ö†Ô∏è  Erro ao acessar URL de busca (status: {status})")
    
    return []

def coletar_produtos_organicos():
    """
    Coleta produtos org√¢nicos fazendo busca global por termos.
    Termos buscados: org√¢nico, organico, organic
    Retorna lista de produtos org√¢nicos encontrados.
    """
    todos_produtos = []
    
    print("=" * 60)
    print("COLETA DE PRODUTOS ORG√ÇNICOS")
    print("ESTRAT√âGIA: Busca Global por Termos")
    print("=" * 60)
    
    termos_busca = ['org√¢nico', 'organico', 'organic']
    
    for termo in termos_busca:
        produtos_busca = buscar_produtos_por_termo(termo)
        # Marca todos como org√¢nicos
        for produto in produtos_busca:
            produto['categoria'] = 'Org√¢nico'
        todos_produtos.extend(produtos_busca)
        
        # Delay entre buscas
        if termo != termos_busca[-1]:
            time.sleep(2)
    
    print(f"\n{'='*60}")
    print(f"TOTAL DE PRODUTOS ORG√ÇNICOS COLETADOS: {len(todos_produtos)}")
    print(f"{'='*60}\n")
    
    return todos_produtos

def coletar_produtos_nao_organicos():
    """
    Coleta produtos n√£o org√¢nicos de categorias espec√≠ficas de alimentos.
    Acessa p√°ginas de categorias alimentares do site.
    Retorna lista de produtos n√£o org√¢nicos encontrados.
    """
    todos_produtos = []
    
    print("=" * 60)
    print("COLETA DE PRODUTOS N√ÉO ORG√ÇNICOS")
    print("ESTRAT√âGIA: Categorias de Alimentos")
    print("=" * 60)
    
    # Categorias de alimentos no Zona Sul
    categorias_alimentos = [
        ('hortifruti', 'Hortifruti'),
        ('mercearia', 'Mercearia'),
        ('laticinios', 'Latic√≠nios'),
        ('carnes', 'Carnes'),
        ('padaria', 'Padaria'),
        ('bebidas', 'Bebidas'),
        ('congelados', 'Congelados'),
        ('frios', 'Frios'),
    ]
    
    for categoria_slug, categoria_nome in categorias_alimentos:
        # URL da categoria (sem /organicos)
        url = f'https://www.zonasul.com.br/{categoria_slug}'
        
        print(f"\nüîç Coletando de: {categoria_nome}")
        print(f"   URL: {url}")
        
        produtos = coletar_todas_paginas(url)
        
        # Marca todos como n√£o org√¢nicos
        for produto in produtos:
            produto['categoria'] = 'N√£o Org√¢nico'
        
        if len(produtos) > 0:
            todos_produtos.extend(produtos)
            print(f"   ‚úÖ {len(produtos)} produtos encontrados em {categoria_nome}")
        else:
            print(f"   ‚ö†Ô∏è  Nenhum produto encontrado em {categoria_nome}")
        
        # Delay entre categorias
        if categoria_slug != categorias_alimentos[-1][0]:
            time.sleep(2)
    
    print(f"\n{'='*60}")
    print(f"TOTAL DE PRODUTOS N√ÉO ORG√ÇNICOS COLETADOS: {len(todos_produtos)}")
    print(f"{'='*60}\n")
    
    return todos_produtos

def processar_dados_para_planilha(produtos):
    """
    Processa os produtos coletados e formata para a planilha.
    Retorna uma lista de dicion√°rios com as colunas: Nome, Quantidade, Unidade, Pre√ßo, Categoria, Tipo
    """
    dados_planilha = []
    
    for produto in produtos:
        nome_bruto = produto['nome_bruto']
        preco = produto['preco_bruto']
        categoria = produto.get('categoria', 'Org√¢nico')
        tipo = produto.get('tipo', 'processados')
        
        # Separa nome e quantidade
        nome_limpo, quantidade, unidade = separar_nome_quantidade(nome_bruto)
        
        # Formata pre√ßo
        if preco is None:
            preco_formatado = "-"
        else:
            try:
                preco_num = float(preco)
                preco_formatado = f"{preco_num:.2f}"
            except (ValueError, TypeError):
                preco_formatado = str(preco) if preco else "-"
        
        # Adiciona √† lista
        dados_planilha.append({
            'Nome': nome_limpo,
            'Quantidade': quantidade,
            'Unidade': unidade,
            'Pre√ßo': preco_formatado,
            'Categoria': categoria,
            'Tipo': tipo
        })
    
    return dados_planilha

def salvar_planilha(produtos, nome_arquivo='produtos_hortifruti_zonasul.xlsx'):
    """
    Salva os produtos coletados em planilhas Excel e CSV.
    Colunas: Nome, Quantidade, Unidade, Pre√ßo, Categoria, Tipo Produto
    """
    if not produtos:
        print("‚ùå Nenhum produto para salvar!")
        return
    
    print("\n" + "=" * 60)
    print("PROCESSANDO DADOS PARA PLANILHA")
    print("=" * 60)
    
    # Processa os dados
    dados_planilha = processar_dados_para_planilha(produtos)
    
    # Cria DataFrame
    df = pd.DataFrame(dados_planilha)
    
    # Remove duplicatas (baseado no nome)
    df_original = df.copy()
    df = df.drop_duplicates(subset=['Nome'], keep='first')
    
    if len(df) < len(df_original):
        print(f"‚ö†Ô∏è  {len(df_original) - len(df)} produtos duplicados removidos")
    
    # Ordena por categoria, tipo e nome
    df = df.sort_values(['Categoria', 'Tipo', 'Nome']).reset_index(drop=True)
    
    # Gera nome do arquivo CSV
    nome_csv = nome_arquivo.replace('.xlsx', '.csv')
    
    # Salva em CSV (sempre)
    try:
        df.to_csv(nome_csv, index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ Planilha CSV salva com sucesso: {nome_csv}")
    except Exception as e:
        print(f"‚ùå Erro ao salvar CSV: {e}")
        nome_csv = None
    
    # Salva em Excel (se poss√≠vel)
    excel_salvo = False
    try:
        df.to_excel(nome_arquivo, index=False, engine='openpyxl')
        print(f"‚úÖ Planilha Excel salva com sucesso: {nome_arquivo}")
        excel_salvo = True
    except ImportError:
        print("‚ö†Ô∏è  openpyxl n√£o est√° instalado. CSV salvo, mas Excel n√£o foi gerado.")
        print("üí° Para salvar em Excel, instale: pip install openpyxl")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao salvar Excel: {e}")
        print("‚úÖ CSV foi salvo com sucesso")
    
    # Mostra resumo
    print(f"\nüìä Total de produtos √∫nicos: {len(df)}")
    
    print("\nüìà Resumo por categoria:")
    resumo = df['Categoria'].value_counts()
    for categoria, count in resumo.items():
        print(f"   - {categoria}: {count}")
    
    print("\nüìà Resumo por tipo:")
    resumo_tipo = df['Tipo'].value_counts()
    for tipo, count in resumo_tipo.items():
        print(f"   - {tipo}: {count}")
    
    # Resumo final dos arquivos gerados
    print("\n" + "=" * 60)
    print("ARQUIVOS GERADOS:")
    if excel_salvo:
        print(f"   ‚úÖ {nome_arquivo}")
    if nome_csv:
        print(f"   ‚úÖ {nome_csv}")
    print("=" * 60)

def main():
    """Fun√ß√£o principal - executa coleta de produtos org√¢nicos e n√£o org√¢nicos e salva planilha"""
    todos_produtos = []
    
    # Coleta produtos org√¢nicos
    produtos_organicos = coletar_produtos_organicos()
    todos_produtos.extend(produtos_organicos)
    
    # Delay entre coletas
    print("\n‚è≥ Aguardando antes de coletar produtos n√£o org√¢nicos...\n")
    time.sleep(3)
    
    # Coleta produtos n√£o org√¢nicos
    produtos_nao_organicos = coletar_produtos_nao_organicos()
    todos_produtos.extend(produtos_nao_organicos)
    
    print("\n" + "=" * 60)
    print("RESUMO DA COLETA COMPLETA")
    print("=" * 60)
    print(f"Total de produtos coletados: {len(todos_produtos)}")
    
    # Conta por categoria
    organicos = [p for p in todos_produtos if p.get('categoria') == 'Org√¢nico']
    nao_organicos = [p for p in todos_produtos if p.get('categoria') == 'N√£o Org√¢nico']
    
    print(f"  - Org√¢nicos: {len(organicos)}")
    print(f"  - N√£o Org√¢nicos: {len(nao_organicos)}")
    
    # Salva na planilha
    salvar_planilha(todos_produtos)
    
    return todos_produtos

if __name__ == "__main__":
    produtos = main()
