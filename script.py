import requests
from bs4 import BeautifulSoup
import json
import time
import re
import pandas as pd
from urllib.parse import quote

# Configura√ß√µes b√°sicas
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
}

def separar_nome_quantidade(nome_bruto):
    """
    Separa o nome do produto da quantidade.
    Procura por padr√µes como: 180g, 600g, 1kg, 500ml, Com 10 Unidades, etc.
    Retorna: (nome_limpo, quantidade, unidade)
    Se n√£o encontrar quantidade: (nome_limpo, "-", "-")
    """
    if not nome_bruto:
        return ("-", "-", "-")
    
    # Padr√£o 1: n√∫mero seguido de unidade no final (180g, 600g, 1kg, 500ml, etc)
    padrao_final = r'(\d+(?:[.,]\d+)?)\s*(g|kg|ml|l)\s*$'
    
    # Padr√£o 2: "Com X Unidades" ou "X Unidades" no final
    padrao_unidades = r'(?:com\s+)?(\d+(?:[.,]\d+)?)\s*(unidades?|un\.?)\s*$'
    
    # Tenta padr√£o final primeiro (mais comum)
    match = re.search(padrao_final, nome_bruto, re.IGNORECASE)
    
    if not match:
        # Tenta padr√£o de unidades
        match = re.search(padrao_unidades, nome_bruto, re.IGNORECASE)
    
    if match:
        # Encontrou quantidade
        quantidade = match.group(1)
        unidade = match.group(2).lower()
        
        # Remove a quantidade do nome (incluindo "Com" se existir)
        nome_limpo = nome_bruto[:match.start()].strip()
        # Remove "Com" se ficou no final do nome
        nome_limpo = re.sub(r'\s+[Cc]om\s*$', '', nome_limpo).strip()
        
        return (nome_limpo, quantidade, unidade)
    else:
        # N√£o encontrou quantidade
        return (nome_bruto.strip(), "-", "-")

def buscar_pagina(url, mostrar_log=False):
    """Faz a requisi√ß√£o e retorna o BeautifulSoup"""
    try:
        if mostrar_log:
            print(f"Acessando: {url}")
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser'), response.status_code
    except requests.exceptions.RequestException as e:
        print(f"Erro ao acessar {url}: {e}")
        return None, None

def extrair_produtos_jsonld(soup):
    """Extrai produtos do JSON-LD estruturado"""
    produtos = []
    
    # Procura scripts JSON-LD
    scripts = soup.find_all('script', type='application/ld+json')
    
    for script in scripts:
        try:
            data = json.loads(script.string)
            
            # Verifica se √© uma lista de produtos
            if data.get('@type') == 'ItemList' and 'itemListElement' in data:
                for item in data['itemListElement']:
                    produto_item = item.get('item', {})
                    
                    if produto_item.get('@type') == 'Product':
                        nome = produto_item.get('name', '')
                        preco_info = produto_item.get('offers', {})
                        
                        # Tenta pegar o pre√ßo
                        preco = None
                        if isinstance(preco_info, dict):
                            preco = preco_info.get('price') or preco_info.get('lowPrice')
                        
                        if nome:
                            produtos.append({
                                'nome_bruto': nome,
                                'preco_bruto': preco
                            })
        except json.JSONDecodeError:
            continue
        except Exception as e:
            print(f"Erro ao processar JSON-LD: {e}")
            continue
    
    return produtos

def coletar_todas_paginas(url_base):
    """
    Coleta produtos de todas as p√°ginas dispon√≠veis.
    Para quando n√£o encontrar mais produtos ou der erro.
    Retorna lista de todos os produtos coletados.
    """
    todos_produtos = []
    pagina = 1
    formato_pagina = None
    
    print(f"\n{'='*60}")
    print(f"Iniciando coleta de todas as p√°ginas")
    print(f"URL base: {url_base}")
    print(f"{'='*60}\n")
    
    while True:
        # Monta URL da p√°gina
        if pagina == 1:
            url = url_base
        else:
            # Detecta formato de pagina√ß√£o na p√°gina 2
            if pagina == 2 and formato_pagina is None:
                # Tenta diferentes formatos de pagina√ß√£o
                formatos_teste = []
                if '?' in url_base:
                    formatos_teste = [
                        f"{url_base}&page={pagina}",
                        f"{url_base}&_page={pagina}",
                        f"{url_base}&from={((pagina-1)*50)}",
                    ]
                else:
                    formatos_teste = [
                        f"{url_base}?page={pagina}",
                        f"{url_base}?_page={pagina}",
                        f"{url_base}?from={((pagina-1)*50)}",
                    ]
                
                # Testa cada formato
                for url_teste in formatos_teste:
                    soup_test, status_test = buscar_pagina(url_teste, mostrar_log=False)
                    if soup_test and status_test == 200:
                        produtos_test = extrair_produtos_jsonld(soup_test)
                        if len(produtos_test) > 0:
                            url = url_teste
                            if '&page=' in url_teste or '?page=' in url_teste:
                                formato_pagina = 'page'
                            elif '&_page=' in url_teste or '?_page=' in url_teste:
                                formato_pagina = '_page'
                            elif '&from=' in url_teste or '?from=' in url_teste:
                                formato_pagina = 'from'
                            print(f"   ‚úÖ Formato de pagina√ß√£o detectado: {formato_pagina}")
                            break
                
                if formato_pagina is None:
                    formato_pagina = 'page'
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
            else:
                # Usa o formato detectado
                if formato_pagina == 'page':
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
                elif formato_pagina == '_page':
                    if '?' in url_base:
                        url = f"{url_base}&_page={pagina}"
                    else:
                        url = f"{url_base}?_page={pagina}"
                elif formato_pagina == 'from':
                    offset = (pagina - 1) * 50
                    if '?' in url_base:
                        url = f"{url_base}&from={offset}"
                    else:
                        url = f"{url_base}?from={offset}"
                else:
                    if '?' in url_base:
                        url = f"{url_base}&page={pagina}"
                    else:
                        url = f"{url_base}?page={pagina}"
        
        print(f"üìÑ P√°gina {pagina}: {url}")
        
        # Busca a p√°gina
        soup, status = buscar_pagina(url)
        
        # Se deu erro ao buscar, para
        if soup is None or status != 200:
            print(f"‚ùå Erro ou p√°gina n√£o encontrada. Parando na p√°gina {pagina}")
            break
        
        # Extrai produtos da p√°gina
        produtos_pagina = extrair_produtos_jsonld(soup)
        
        # Se n√£o encontrou produtos, acabaram as p√°ginas
        if len(produtos_pagina) == 0:
            print(f"‚úÖ Fim das p√°ginas (p√°gina {pagina} n√£o tem produtos)")
            break
        
        # Adiciona categoria e metadados
        for produto in produtos_pagina:
            produto['categoria'] = 'Org√¢nico'
            produto['url_origem'] = url
        
        # Adiciona produtos encontrados
        todos_produtos.extend(produtos_pagina)
        print(f"   ‚úÖ {len(produtos_pagina)} produtos encontrados (Total: {len(todos_produtos)})\n")
        
        pagina += 1
        
        # Delay para n√£o sobrecarregar o servidor
        time.sleep(1)
    
    print(f"\n{'='*60}")
    print(f"Coleta conclu√≠da: {len(todos_produtos)} produtos em {pagina-1} p√°ginas")
    print(f"{'='*60}\n")
    
    return todos_produtos

def buscar_produtos_por_termo(termo_busca):
    """
    Busca produtos org√¢nicos por termo usando o formato correto:
    https://www.zonasul.com.br/organico?_q={termo}&map=ft
    Retorna lista de produtos encontrados.
    """
    # Codifica o termo de busca para URL
    termo_encoded = quote(termo_busca, safe='')
    
    # URL de busca do Zona Sul no formato correto
    url_busca = f'https://www.zonasul.com.br/organico?_q={termo_encoded}&map=ft'
    
    print(f"\nüîç Buscando por termo: '{termo_busca}'")
    print(f"   URL: {url_busca}")
    
    # Verifica se a URL existe e tem produtos
    soup, status = buscar_pagina(url_busca, mostrar_log=False)
    
    if soup is not None and status == 200:
        produtos_teste = extrair_produtos_jsonld(soup)
        if len(produtos_teste) > 0:
            print(f"   ‚úÖ URL de busca acess√≠vel com produtos encontrados")
            produtos = coletar_todas_paginas(url_busca)
            print(f"   üìä {len(produtos)} produtos encontrados para '{termo_busca}'")
            return produtos
        else:
            print(f"   ‚ö†Ô∏è  URL acess√≠vel mas nenhum produto encontrado na primeira p√°gina")
    else:
        print(f"   ‚ö†Ô∏è  Erro ao acessar URL de busca (status: {status})")
    
    return []

def coletar_produtos_organicos():
    """
    Coleta produtos org√¢nicos fazendo busca global por termos.
    Termos buscados: organico, org√¢nico, organic, organicos, org√¢nicos
    Retorna lista de produtos org√¢nicos encontrados.
    """
    todos_produtos = []
    
    print("=" * 60)
    print("COLETA DE PRODUTOS ORG√ÇNICOS")
    print("ESTRAT√âGIA: Busca Global por Termos")
    print("=" * 60)
    
    termos_busca = ['organico', 'org√¢nico', 'organic', 'organicos', 'org√¢nicos']
    
    for termo in termos_busca:
        produtos_busca = buscar_produtos_por_termo(termo)
        todos_produtos.extend(produtos_busca)
        
        # Delay entre buscas
        if termo != termos_busca[-1]:
            time.sleep(2)
    
    print(f"\n{'='*60}")
    print(f"TOTAL DE PRODUTOS ORG√ÇNICOS COLETADOS: {len(todos_produtos)}")
    print(f"{'='*60}\n")
    
    return todos_produtos

def processar_dados_para_planilha(produtos):
    """
    Processa os produtos coletados e formata para a planilha.
    Retorna uma lista de dicion√°rios com as colunas: Nome, Quantidade, Unidade, Pre√ßo, Categoria, Tipo Produto
    """
    dados_planilha = []
    
    for produto in produtos:
        nome_bruto = produto['nome_bruto']
        preco = produto['preco_bruto']
        categoria = produto['categoria']
        
        # Separa nome e quantidade
        nome_limpo, quantidade, unidade = separar_nome_quantidade(nome_bruto)
        
        # Formata pre√ßo
        if preco is None:
            preco_formatado = "-"
        else:
            try:
                preco_num = float(preco)
                preco_formatado = f"{preco_num:.2f}"
            except (ValueError, TypeError):
                preco_formatado = str(preco) if preco else "-"
        
        # Adiciona √† lista
        dados_planilha.append({
            'Nome': nome_limpo,
            'Quantidade': quantidade,
            'Unidade': unidade,
            'Pre√ßo': preco_formatado,
            'Categoria': categoria,
        })
    
    return dados_planilha

def salvar_planilha(produtos, nome_arquivo='produtos_hortifruti_zonasul.xlsx'):
    """
    Salva os produtos coletados em planilhas Excel e CSV.
    Colunas: Nome, Quantidade, Unidade, Pre√ßo, Categoria, Tipo Produto
    """
    if not produtos:
        print("‚ùå Nenhum produto para salvar!")
        return
    
    print("\n" + "=" * 60)
    print("PROCESSANDO DADOS PARA PLANILHA")
    print("=" * 60)
    
    # Processa os dados
    dados_planilha = processar_dados_para_planilha(produtos)
    
    # Cria DataFrame
    df = pd.DataFrame(dados_planilha)
    
    # Remove duplicatas (baseado no nome)
    df_original = df.copy()
    df = df.drop_duplicates(subset=['Nome'], keep='first')
    
    if len(df) < len(df_original):
        print(f"‚ö†Ô∏è  {len(df_original) - len(df)} produtos duplicados removidos")
    
    # Ordena por categoria e nome
    df = df.sort_values(['Categoria', 'Nome']).reset_index(drop=True)
    
    # Gera nome do arquivo CSV
    nome_csv = nome_arquivo.replace('.xlsx', '.csv')
    
    # Salva em CSV (sempre)
    try:
        df.to_csv(nome_csv, index=False, encoding='utf-8-sig')
        print(f"\n‚úÖ Planilha CSV salva com sucesso: {nome_csv}")
    except Exception as e:
        print(f"‚ùå Erro ao salvar CSV: {e}")
        nome_csv = None
    
    # Salva em Excel (se poss√≠vel)
    excel_salvo = False
    try:
        df.to_excel(nome_arquivo, index=False, engine='openpyxl')
        print(f"‚úÖ Planilha Excel salva com sucesso: {nome_arquivo}")
        excel_salvo = True
    except ImportError:
        print("‚ö†Ô∏è  openpyxl n√£o est√° instalado. CSV salvo, mas Excel n√£o foi gerado.")
        print("üí° Para salvar em Excel, instale: pip install openpyxl")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao salvar Excel: {e}")
        print("‚úÖ CSV foi salvo com sucesso")
    
    # Mostra resumo
    print(f"\nüìä Total de produtos √∫nicos: {len(df)}")
    
    print("\nüìà Resumo por categoria:")
    resumo = df['Categoria'].value_counts()
    for categoria, count in resumo.items():
        print(f"   - {categoria}: {count}")
    
    # Resumo final dos arquivos gerados
    print("\n" + "=" * 60)
    print("ARQUIVOS GERADOS:")
    if excel_salvo:
        print(f"   ‚úÖ {nome_arquivo}")
    if nome_csv:
        print(f"   ‚úÖ {nome_csv}")
    print("=" * 60)

def main():
    """Fun√ß√£o principal - executa coleta de produtos org√¢nicos e salva planilha"""
    produtos = coletar_produtos_organicos()
    
    print("\n" + "=" * 60)
    print("RESUMO DA COLETA")
    print("=" * 60)
    print(f"Total de produtos coletados: {len(produtos)}")
    
    # Salva na planilha
    salvar_planilha(produtos)
    
    return produtos

if __name__ == "__main__":
    produtos = main()
